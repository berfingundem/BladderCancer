{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCi2TqOXiEf/Xcd8NtSdJF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/berfingundem/BladderCancer/blob/main/SwinHiperparametreCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJvt2HqmSRdP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from collections import Counter\n",
        "import timm\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- GPU ayarı ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Kullanılan cihaz:\", device)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- Veri yolu ---\n",
        "data_dir = \"/content/drive/MyDrive/bladder_sett\"  # dataset sadece HGC, LGC, NST, NTL klasörlerini içermeli\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "dataset = ImageFolder(data_dir, transform=transform)\n",
        "class_names = dataset.classes  # ['HGC','LGC','NST','NTL']\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# --- Parametreler ---\n",
        "batch_size = 16\n",
        "num_epochs = 30\n",
        "k_folds = 5\n",
        "patience = 5  # early stopping için sabır\n",
        "\n",
        "# --- K-Fold Cross Validation ---\n",
        "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "fold_results = {}\n",
        "\n",
        "for fold, (train_ids, val_ids) in enumerate(kfold.split(dataset)):\n",
        "    print(f\"\\n--- Fold {fold+1}/{k_folds} ---\")\n",
        "\n",
        "    # Subset oluştur\n",
        "    train_subsampler = Subset(dataset, train_ids)\n",
        "    val_subsampler = Subset(dataset, val_ids)\n",
        "\n",
        "    train_loader = DataLoader(train_subsampler, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_subsampler, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # --- Class Weights Hesapla (Fold içinde yoksa 1 olarak al) ---\n",
        "    targets = [dataset.targets[i] for i in train_ids]\n",
        "    class_counts = Counter(targets)\n",
        "    class_weights = []\n",
        "\n",
        "    total = float(sum(class_counts.values()))\n",
        "    for i in range(num_classes):\n",
        "        count = class_counts.get(i, 0)\n",
        "        if count == 0:\n",
        "            count = 1  # fold içinde sınıf yoksa 1 al\n",
        "        class_weights.append(total / (num_classes * count))\n",
        "\n",
        "    # CPU'da tensor oluştur, sonra CUDA'ya gönder\n",
        "    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "    # --- Model ---\n",
        "    model = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True, num_classes=num_classes)\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
        "\n",
        "    # Early Stopping değişkenleri\n",
        "    best_val_loss = np.inf\n",
        "    patience_counter = 0\n",
        "\n",
        "    train_loss_list, val_loss_list = [], []\n",
        "    train_acc_list, val_acc_list = [], []\n",
        "\n",
        "    # --- Eğitim Döngüsü ---\n",
        "    for epoch in range(num_epochs):\n",
        "        # --- Eğitim ---\n",
        "        model.train()\n",
        "        train_loss, correct, total_samples = 0, 0, 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "        train_acc = correct / total_samples\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        # --- Doğrulama ---\n",
        "        model.eval()\n",
        "        val_loss, correct, total_samples = 0, 0, 0\n",
        "        y_true, y_pred, y_score = [], [], []\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                probs = torch.softmax(outputs, dim=1)\n",
        "                _, predicted = outputs.max(1)\n",
        "\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "                total_samples += labels.size(0)\n",
        "\n",
        "                y_true.extend(labels.cpu().numpy())\n",
        "                y_pred.extend(predicted.cpu().numpy())\n",
        "                y_score.extend(probs.cpu().numpy())\n",
        "\n",
        "        val_acc = correct / total_samples\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        # Kayıt\n",
        "        train_loss_list.append(train_loss)\n",
        "        val_loss_list.append(val_loss)\n",
        "        train_acc_list.append(train_acc)\n",
        "        val_acc_list.append(val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
        "              f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n",
        "              f\"Train Acc: {train_acc:.2f} | Val Acc: {val_acc:.2f}\")\n",
        "\n",
        "        # LR Scheduler güncelle\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Early Stopping kontrol\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            best_model_wts = model.state_dict()\n",
        "            best_y_true, best_y_pred, best_y_score = y_true[:], y_pred[:], y_score[:]\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early stopping tetiklendi.\")\n",
        "                break\n",
        "\n",
        "    # En iyi model yükle\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    # Fold sonuçlarını kaydet\n",
        "    fold_results[fold] = {\n",
        "        'train_acc': train_acc_list,\n",
        "        'val_acc': val_acc_list,\n",
        "        'train_loss': train_loss_list,\n",
        "        'val_loss': val_loss_list,\n",
        "        'y_true': best_y_true,\n",
        "        'y_pred': best_y_pred,\n",
        "        'y_score': np.array(best_y_score)\n",
        "    }\n",
        "\n",
        "    # --- Konfüzyon Matrisi (sadece HGC, LGC, NST, NTL) ---\n",
        "    cm = confusion_matrix(best_y_true, best_y_pred, labels=list(range(num_classes)))\n",
        "    plt.figure(figsize=(6, 5), dpi=300)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(f'Fold {fold+1} - Konfüzyon Matrisi')\n",
        "    plt.xlabel('Tahmin')\n",
        "    plt.ylabel('Gerçek')\n",
        "    plt.show()\n",
        "\n",
        "    # --- ROC Eğrisi ---\n",
        "    y_true_bin = label_binarize(best_y_true, classes=list(range(num_classes)))\n",
        "    fpr, tpr, roc_auc = {}, {}, {}\n",
        "    for i in range(num_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], fold_results[fold]['y_score'][:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    plt.figure(figsize=(7, 6), dpi=300)\n",
        "    for i in range(num_classes):\n",
        "        plt.plot(fpr[i], tpr[i], label=f\"{class_names[i]} (AUC={roc_auc[i]:.2f})\")\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.title(f'Fold {fold+1} - ROC Eğrisi')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# --- Fold ortalama doğruluk ---\n",
        "all_val_acc = [max(fold_results[f]['val_acc']) for f in fold_results]\n",
        "print(\"\\nK-Fold ortalama doğruluk:\", np.mean(all_val_acc))\n"
      ]
    }
  ]
}