{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZnHiD/pB2omyWQCviMCRp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/berfingundem/BladderCancer/blob/main/ViTCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbhuHu4JIM6m"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import timm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Google Drive bağlantısı\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Veri dizini (Google Drive)\n",
        "data_dir = \"/content/drive/MyDrive/bladder_set\"\n",
        "class_names = ['LGC', 'NTL', 'HGC', 'NST']  # Define your class names based on your folders\n",
        "\n",
        "# Eğitim ve doğrulama klasörlerini oluşturma\n",
        "train_dir = os.path.join(data_dir, \"train\")\n",
        "val_dir = os.path.join(data_dir, \"val\")\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "\n",
        "# Her sınıf için verileri ayırma (Eğitim ve doğrulama)\n",
        "for class_name in class_names:\n",
        "    class_path = os.path.join(data_dir, class_name)\n",
        "    images = os.listdir(class_path)\n",
        "    train_images, val_images = train_test_split(images, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Eğitim ve doğrulama klasörlerine taşıma\n",
        "    train_class_dir = os.path.join(train_dir, class_name)\n",
        "    val_class_dir = os.path.join(val_dir, class_name)\n",
        "    os.makedirs(train_class_dir, exist_ok=True)\n",
        "    os.makedirs(val_class_dir, exist_ok=True)\n",
        "\n",
        "    for image in train_images:\n",
        "        shutil.copy(os.path.join(class_path, image), os.path.join(train_class_dir, image))\n",
        "\n",
        "    for image in val_images:\n",
        "        shutil.copy(os.path.join(class_path, image), os.path.join(val_class_dir, image))\n",
        "\n",
        "# Görsel dönüşümleri\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "# Eğitim ve doğrulama verileri\n",
        "train_dataset = ImageFolder(os.path.join(data_dir, 'train'), transform=transform)\n",
        "val_dataset = ImageFolder(os.path.join(data_dir, 'val'), transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "class_names = train_dataset.classes\n",
        "num_classes = len(class_names)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=num_classes)\n",
        "model.to(device)\n",
        "\n",
        "# Eğitim bileşenleri\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Eğitim ayarları\n",
        "num_epochs = 14\n",
        "train_loss_list, val_loss_list = [], []\n",
        "train_acc_list, val_acc_list = [], []\n",
        "\n",
        "# Eğitim döngüsü\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_acc = correct / total\n",
        "    train_loss /= len(train_loader)\n",
        "    train_acc_list.append(train_acc)\n",
        "    train_loss_list.append(train_loss)\n",
        "\n",
        "    # Doğrulama\n",
        "    model.eval()\n",
        "    val_loss, correct, total = 0, 0, 0\n",
        "    y_true, y_pred, y_score = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "            y_score.extend(probs.cpu().numpy())\n",
        "\n",
        "    val_acc = correct / total\n",
        "    val_loss /= len(val_loader)\n",
        "    val_acc_list.append(val_acc)\n",
        "    val_loss_list.append(val_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Acc: {train_acc:.2f} | Val Acc: {val_acc:.2f}\")\n",
        "\n",
        "# --- GÖRSEL 1: Loss ve Accuracy Eğrileri ---\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_acc_list, label='Train Accuracy')\n",
        "plt.plot(val_acc_list, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy Eğrisi')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_loss_list, label='Train Loss')\n",
        "plt.plot(val_loss_list, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Eğrisi')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- GÖRSEL 2: Konfüzyon Matrisleri (Ham & Normalize) ---\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6), dpi=300)\n",
        "\n",
        "# Ham değerler\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=class_names, yticklabels=class_names,\n",
        "            cbar=False, annot_kws={\"size\": 12}, ax=axes[0])\n",
        "axes[0].set_title(\"Confusion Matrix (Counts)\", fontsize=14)\n",
        "axes[0].set_xlabel(\"Predicted Label\")\n",
        "axes[0].set_ylabel(\"True Label\")\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "axes[0].tick_params(axis='y', rotation=0)\n",
        "\n",
        "# Normalize değerler\n",
        "sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
        "            xticklabels=class_names, yticklabels=class_names,\n",
        "            cbar=False, annot_kws={\"size\": 12}, ax=axes[1])\n",
        "axes[1].set_title(\"Confusion Matrix (Normalized)\", fontsize=14)\n",
        "axes[1].set_xlabel(\"Predicted Label\")\n",
        "axes[1].set_ylabel(\"True Label\")\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "axes[1].tick_params(axis='y', rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# --- GÖRSEL 3: ROC Eğrisi ---\n",
        "y_true_bin = label_binarize(y_true, classes=list(range(num_classes)))\n",
        "y_score = np.array(y_score)\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(num_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "plt.figure(figsize=(8, 6), dpi=300)\n",
        "for i in range(num_classes):\n",
        "    plt.plot(fpr[i], tpr[i], label=f\"{class_names[i]} (AUC = {roc_auc[i]:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Eğrisi')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ]
}